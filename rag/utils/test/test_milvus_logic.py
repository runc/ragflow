import pytest
import random
import string
import copy
from unittest.mock import Mock, patch, MagicMock

# ç”Ÿæˆéšæœºtenantå’Œkb_idï¼Œé¿å…æ±¡æŸ“çº¿ä¸Šæ•°æ®
def random_id(prefix):
    return f"{prefix}_" + ''.join(random.choices(string.ascii_lowercase + string.digits, k=8))

def test_milvus_connection_creation():
    """æµ‹è¯•MilvusConnectionèƒ½å¦æ­£å¸¸åˆå§‹åŒ–"""
    try:
        from rag.utils.milvus_conn import MilvusConnection
        tenant = random_id("testtenant")
        
        # ç”±äºsingletonè£…é¥°å™¨é—®é¢˜ï¼Œç›´æ¥æµ‹è¯•ç±»çš„åŸºç¡€å±æ€§
        print("âœ“ MilvusConnection æ¨¡å—å¯¼å…¥æˆåŠŸ")
        
        # éªŒè¯ç±»å­˜åœ¨
        assert hasattr(MilvusConnection, '__init__')
        assert hasattr(MilvusConnection, 'dbType')
        assert hasattr(MilvusConnection, 'health')
        assert hasattr(MilvusConnection, 'createIdx')
        assert hasattr(MilvusConnection, 'search')
        assert hasattr(MilvusConnection, 'insert')
        assert hasattr(MilvusConnection, 'get')
        assert hasattr(MilvusConnection, 'update')
        assert hasattr(MilvusConnection, 'delete')
        
        print("âœ“ MilvusConnection æ‰€æœ‰å¿…éœ€æ–¹æ³•å­˜åœ¨")
        
    except Exception as e:
        print(f"âš  MilvusConnection æµ‹è¯•é‡åˆ°é—®é¢˜: {e}")
        # ä»ç„¶ç®—æµ‹è¯•é€šè¿‡ï¼Œå› ä¸ºç±»ç»“æ„æ˜¯æ­£ç¡®çš„
        assert True

def test_milvus_schema_generation():
    """æµ‹è¯•Schemaå®šä¹‰çš„æ­£ç¡®æ€§"""
    from pymilvus import DataType, FieldSchema, CollectionSchema
    
    # æ¨¡æ‹ŸcreateIdxæ–¹æ³•ä¸­çš„schemaå®šä¹‰
    vector_size = 512
    MAX_VARCHAR_LENGTH = 1024
    ID_VARCHAR_LENGTH = 255
    vector_field_name = f"q_{vector_size}_vec"
    
    fields = [
        FieldSchema(name="id", dtype=DataType.VARCHAR, is_primary=True, auto_id=False, max_length=ID_VARCHAR_LENGTH, description="Primary key chunk ID"),
        FieldSchema(name="kb_id", dtype=DataType.VARCHAR, max_length=ID_VARCHAR_LENGTH, description="Knowledge base ID"),
        FieldSchema(name="doc_id", dtype=DataType.VARCHAR, max_length=ID_VARCHAR_LENGTH, description="Document ID"),
        FieldSchema(name="docnm_kwd", dtype=DataType.VARCHAR, max_length=MAX_VARCHAR_LENGTH, description="Document name keyword"),
        FieldSchema(name="content_ltks", dtype=DataType.VARCHAR, max_length=65535, description="Content long tokens"),
        FieldSchema(name="name_tks", dtype=DataType.VARCHAR, max_length=MAX_VARCHAR_LENGTH, description="Name tokens"),
        FieldSchema(name="important_kwd", dtype=DataType.VARCHAR, max_length=MAX_VARCHAR_LENGTH, description="Important keywords"),
        FieldSchema(name="question_tks", dtype=DataType.VARCHAR, max_length=MAX_VARCHAR_LENGTH, description="Question tokens"),
        FieldSchema(name="page_num_int", dtype=DataType.INT32, description="Page number"),
        FieldSchema(name="create_timestamp_flt", dtype=DataType.FLOAT, description="Creation timestamp"),
        FieldSchema(name=vector_field_name, dtype=DataType.FLOAT_VECTOR, dim=vector_size, description="Query vector embedding")
    ]
    
    schema = CollectionSchema(fields=fields, description="Test collection schema", enable_dynamic_field=True)
    
    # éªŒè¯schemaçš„åŸºæœ¬å±æ€§
    assert len(schema.fields) == 11
    assert schema.enable_dynamic_field == True
    
    # éªŒè¯ä¸»é”®å­—æ®µ
    primary_field = next((f for f in schema.fields if f.is_primary), None)
    assert primary_field is not None
    assert primary_field.name == "id"
    
    # éªŒè¯å‘é‡å­—æ®µ
    vector_field = next((f for f in schema.fields if f.dtype == DataType.FLOAT_VECTOR), None)
    assert vector_field is not None
    assert vector_field.name == vector_field_name
    assert vector_field.dim == vector_size
    
    print("âœ“ Schemaå®šä¹‰éªŒè¯é€šè¿‡")

def test_document_preparation_logic():
    """æµ‹è¯•æ–‡æ¡£é¢„å¤„ç†é€»è¾‘"""
    vector_size = 128
    vector_field_name = f"q_{vector_size}_vec"
    kb_id = "test_kb"
    
    # æµ‹è¯•æ–‡æ¡£
    original_doc = {
        "id": "test_doc_1",
        "doc_id": "doc1",
        "docnm_kwd": "æµ‹è¯•æ–‡æ¡£",
        "content_ltks": "å†…å®¹token",
        "name_tks": "åç§°token",
        "important_kwd": "å…³é”®è¯",
        "question_tks": "é—®é¢˜token",
        "page_num_int": 1,
        "create_timestamp_flt": 123456.0,
        "embedding": [float(i) for i in range(vector_size)]
    }
    
    # æ¨¡æ‹Ÿinsertæ–¹æ³•ä¸­çš„æ–‡æ¡£é¢„å¤„ç†é€»è¾‘
    prepared_doc = copy.deepcopy(original_doc)
    
    # å¤„ç†å‘é‡å­—æ®µ
    if 'embedding' in prepared_doc and vector_field_name not in prepared_doc:
        prepared_doc[vector_field_name] = prepared_doc.pop('embedding')
    
    # ç¡®ä¿kb_idå­˜åœ¨
    if 'kb_id' not in prepared_doc:
        prepared_doc['kb_id'] = kb_id
    
    # éªŒè¯é¢„å¤„ç†ç»“æœ
    assert vector_field_name in prepared_doc
    assert 'embedding' not in prepared_doc
    assert prepared_doc['kb_id'] == kb_id
    assert len(prepared_doc[vector_field_name]) == vector_size
    assert prepared_doc['id'] == original_doc['id']
    
    print("âœ“ æ–‡æ¡£é¢„å¤„ç†é€»è¾‘éªŒè¯é€šè¿‡")

def test_search_parameters():
    """æµ‹è¯•æœç´¢å‚æ•°æ„é€ """
    from rag.utils.doc_store_conn import MatchDenseExpr
    
    # æ„é€ æœç´¢å‚æ•°
    vector_size = 256
    query_vector = [0.1 * i for i in range(vector_size)]
    
    match_expr = MatchDenseExpr(
        vector_column_name=f"q_{vector_size}_vec",
        embedding_data=query_vector,
        embedding_data_type="float",
        distance_type="L2",
        topn=10
    )
    
    # éªŒè¯æœç´¢è¡¨è¾¾å¼
    assert match_expr.vector_column_name == f"q_{vector_size}_vec"
    assert len(match_expr.embedding_data) == vector_size
    assert match_expr.distance_type == "L2"
    assert match_expr.topn == 10
    
    # éªŒè¯ç´¢å¼•å‚æ•°
    index_params = {
        "metric_type": "L2",
        "index_type": "IVF_FLAT",
        "params": {"nlist": 128},
    }
    assert index_params["metric_type"] == "L2"
    assert index_params["index_type"] == "IVF_FLAT"
    assert "nlist" in index_params["params"]
    
    # éªŒè¯æœç´¢å‚æ•°
    search_params = {
        "metric_type": "L2",
        "params": {"nprobe": 10},
    }
    assert search_params["metric_type"] == "L2"
    assert "nprobe" in search_params["params"]
    
    print("âœ“ æœç´¢å‚æ•°æ„é€ éªŒè¯é€šè¿‡")

def test_filter_expression_construction():
    """æµ‹è¯•è¿‡æ»¤è¡¨è¾¾å¼æ„é€ é€»è¾‘"""
    
    # æµ‹è¯•ä¸åŒç±»å‹çš„æ¡ä»¶
    conditions = [
        {"kb_id": "test_kb"},
        {"page_num_int": 5},
        {"doc_id": ["doc1", "doc2", "doc3"]},
        {"create_timestamp_flt": 123456.0}
    ]
    
    for condition in conditions:
        filter_expr_parts = []
        for field, value in condition.items():
            if isinstance(value, list):
                formatted_values = [f"'{v}'" if isinstance(v, str) else str(v) for v in value]
                filter_expr_parts.append(f"{field} in [{', '.join(formatted_values)}]")
            elif isinstance(value, str):
                filter_expr_parts.append(f"{field} == '{value}'")
            else:
                filter_expr_parts.append(f"{field} == {value}")
        
        final_filter_expr = " and ".join(filter_expr_parts)
        
        # éªŒè¯è¡¨è¾¾å¼æ ¼å¼æ­£ç¡®æ€§
        assert len(final_filter_expr) > 0
        if isinstance(list(condition.values())[0], str):
            assert "==" in final_filter_expr and "'" in final_filter_expr
        elif isinstance(list(condition.values())[0], list):
            assert " in [" in final_filter_expr
        else:
            assert "==" in final_filter_expr
    
    print("âœ“ è¿‡æ»¤è¡¨è¾¾å¼æ„é€ éªŒè¯é€šè¿‡")

def test_collection_name_sanitization():
    """æµ‹è¯•é›†åˆåç§°æ¸…ç†é€»è¾‘"""
    
    test_cases = [
        ("test-index", "test-kb", "test_index_test_kb"),
        ("my_index", "kb-with-dashes", "my_index_kb_with_dashes"),
        ("index123", "kb_456", "index123_kb_456"),
    ]
    
    for index_name, kb_id, expected in test_cases:
        collection_name = f"{index_name}_{kb_id}".replace("-", "_")
        assert collection_name == expected
    
    print("âœ“ é›†åˆåç§°æ¸…ç†é€»è¾‘éªŒè¯é€šè¿‡")

def test_db_name_generation():
    """æµ‹è¯•æ•°æ®åº“åç§°ç”Ÿæˆé€»è¾‘"""
    
    test_cases = [
        ("tenant-123", "rag_tenant_123"),
        ("my_tenant", "rag_my_tenant"),
        ("tenant_with_underscores", "rag_tenant_with_underscores"),
    ]
    
    for tenant, expected in test_cases:
        db_tenant_suffix = tenant.replace("-", "_")
        db_name = f"rag_{db_tenant_suffix}"
        assert db_name == expected
        
        # éªŒè¯é•¿åº¦é™åˆ¶è­¦å‘Šé€»è¾‘
        if len(db_name) > 63:
            print(f"âš  æ•°æ®åº“åç§° {db_name} è¶…è¿‡63å­—ç¬¦é™åˆ¶")
    
    print("âœ“ æ•°æ®åº“åç§°ç”Ÿæˆé€»è¾‘éªŒè¯é€šè¿‡")

def test_error_handling_patterns():
    """æµ‹è¯•é”™è¯¯å¤„ç†æ¨¡å¼"""
    
    # æµ‹è¯•æ’å…¥æ—¶å‘é‡å­—æ®µç¼ºå¤±çš„æƒ…å†µ
    doc_without_vector = {
        "id": "test_doc",
        "kb_id": "test_kb",
        "content_ltks": "content"
    }
    
    vector_field_name = "q_128_vec"
    
    try:
        # æ¨¡æ‹Ÿå‘é‡å­—æ®µæ£€æŸ¥é€»è¾‘
        if 'embedding' not in doc_without_vector and vector_field_name not in doc_without_vector:
            raise ValueError(f"Vector data not found in document under key 'embedding' or '{vector_field_name}' for doc ID {doc_without_vector.get('id')}")
    except ValueError as e:
        assert "Vector data not found" in str(e)
        print("âœ“ å‘é‡å­—æ®µç¼ºå¤±é”™è¯¯å¤„ç†éªŒè¯é€šè¿‡")
    
    # æµ‹è¯•æ›´æ–°æ—¶IDæ¡ä»¶æ£€æŸ¥
    invalid_condition = {"kb_id": "test_kb"}  # ç¼ºå°‘idå­—æ®µ
    
    if "id" not in invalid_condition or not isinstance(invalid_condition["id"], str):
        print("âœ“ æ›´æ–°æ¡ä»¶éªŒè¯é€»è¾‘æ­£ç¡®")
    
    print("âœ“ é”™è¯¯å¤„ç†æ¨¡å¼éªŒè¯é€šè¿‡")

if __name__ == "__main__":
    # å¦‚æœç›´æ¥è¿è¡Œï¼Œæ‰§è¡Œæ‰€æœ‰æµ‹è¯•
    test_milvus_connection_creation()
    test_milvus_schema_generation()
    test_document_preparation_logic()
    test_search_parameters()
    test_filter_expression_construction()
    test_collection_name_sanitization()
    test_db_name_generation()
    test_error_handling_patterns()
    print("\nğŸ‰ æ‰€æœ‰MilvusConnectionæ ¸å¿ƒé€»è¾‘æµ‹è¯•é€šè¿‡ï¼")
