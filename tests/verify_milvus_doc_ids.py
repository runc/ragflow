#!/usr/bin/env python3
"""
éªŒè¯ Milvus ä¸­çš„ doc_id å­—æ®µå€¼
"""

import os
import sys
import logging

# è®¾ç½®ç¯å¢ƒå˜é‡
os.environ['DOC_ENGINE'] = 'milvus'

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'ragflow'))

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def verify_milvus_doc_ids():
    """éªŒè¯ Milvus ä¸­çš„ doc_id å­—æ®µå€¼"""
    try:
        logger.info("=== éªŒè¯ Milvus ä¸­çš„ doc_id å­—æ®µå€¼ ===")
        
        from rag.utils.milvus_conn import MilvusConnection
        from rag.utils.doc_store_conn import OrderByExpr
        from pymilvus import Collection
        
        # åˆ›å»ºè¿æ¥
        conn = MilvusConnection()
        
        # ä½¿ç”¨å·²çŸ¥æœ‰æ•°æ®çš„é›†åˆ
        collection_name = "ragflow_7179adc24c1b11f0bb2a6b89a3fc27c2_7b5bf8b84c1b11f0bb2a6b89a3fc27c2"
        index_name = "ragflow_7179adc24c1b11f0bb2a6b89a3fc27c2"
        kb_id = "7b5bf8b84c1b11f0bb2a6b89a3fc27c2"
        target_doc_id = "a106ea544ce911f0ae6b5df10d5df26e"
        
        logger.info(f"æµ‹è¯•é›†åˆ: {collection_name}")
        logger.info(f"ç›®æ ‡æ–‡æ¡£ID: {target_doc_id}")
        
        # è·å–é›†åˆä¿¡æ¯
        collection = Collection(name=collection_name, using=conn.alias)
        collection.load()
        
        logger.info(f"é›†åˆå®ä½“æ•°: {collection.num_entities}")
        
        # 1. å…ˆè·å–æ‰€æœ‰ doc_id å€¼ï¼Œçœ‹çœ‹å®é™…æœ‰ä»€ä¹ˆ
        logger.info("\n=== è·å–æ‰€æœ‰ doc_id å€¼ ===")
        all_docs_res = conn.search(
            selectFields=["id", "doc_id", "kb_id"],
            highlightFields=[],
            condition={},  # æ— è¿‡æ»¤æ¡ä»¶
            matchExprs=[],
            orderBy=OrderByExpr(),
            offset=0,
            limit=50,  # è·å–æ›´å¤šç»“æœ
            indexNames=[index_name],
            knowledgebaseIds=[kb_id]
        )
        
        total = conn.getTotal(all_docs_res)
        chunk_ids = conn.getChunkIds(all_docs_res)
        logger.info(f"æ— è¿‡æ»¤æ¡ä»¶æœç´¢ç»“æœ - æ€»æ•°: {total}, è¿”å›æ•°é‡: {len(chunk_ids)}")
        
        if total > 0:
            fields = conn.getFields(all_docs_res, ["id", "doc_id", "kb_id"])
            logger.info("å‰10ä¸ªæ–‡æ¡£çš„doc_idå€¼:")
            doc_id_counts = {}
            for i, (chunk_id, data) in enumerate(fields.items()):
                if i < 10:
                    logger.info(f"  Chunk {i+1}: id={chunk_id}, doc_id='{data.get('doc_id', 'N/A')}', kb_id='{data.get('kb_id', 'N/A')}'")
                
                # ç»Ÿè®¡doc_id
                doc_id_val = data.get('doc_id', '')
                doc_id_counts[doc_id_val] = doc_id_counts.get(doc_id_val, 0) + 1
            
            logger.info(f"\ndoc_id ç»Ÿè®¡:")
            for doc_id, count in doc_id_counts.items():
                logger.info(f"  '{doc_id}': {count} chunks")
                if doc_id == target_doc_id:
                    logger.info(f"  âœ“ æ‰¾åˆ°ç›®æ ‡æ–‡æ¡£ID: {target_doc_id}")
        
        # 2. å°è¯•ä½¿ç”¨è¿‡æ»¤æ¡ä»¶æœç´¢
        logger.info(f"\n=== æµ‹è¯•è¿‡æ»¤æ¡ä»¶æœç´¢ ===")
        logger.info(f"ç›®æ ‡doc_id: '{target_doc_id}'")
        
        # æµ‹è¯•ä¸åŒçš„è¿‡æ»¤æ¡ä»¶æ ¼å¼
        test_conditions = [
            {"doc_id": target_doc_id},
            {"doc_id": [target_doc_id]},
        ]
        
        for i, condition in enumerate(test_conditions):
            logger.info(f"\n--- æµ‹è¯•æ¡ä»¶ {i+1}: {condition} ---")
            filtered_res = conn.search(
                selectFields=["id", "doc_id", "kb_id"],
                highlightFields=[],
                condition=condition,
                matchExprs=[],
                orderBy=OrderByExpr(),
                offset=0,
                limit=10,
                indexNames=[index_name],
                knowledgebaseIds=[kb_id]
            )
            
            total = conn.getTotal(filtered_res)
            chunk_ids = conn.getChunkIds(filtered_res)
            logger.info(f"è¿‡æ»¤æœç´¢ç»“æœ - æ€»æ•°: {total}, è¿”å›æ•°é‡: {len(chunk_ids)}")
            
            if total > 0:
                fields = conn.getFields(filtered_res, ["id", "doc_id", "kb_id"])
                logger.info("åŒ¹é…çš„ç»“æœ:")
                for chunk_id, data in fields.items():
                    logger.info(f"  id={chunk_id}, doc_id='{data.get('doc_id', 'N/A')}'")
            else:
                logger.warning("  âŒ æ²¡æœ‰æ‰¾åˆ°åŒ¹é…ç»“æœ")
        
        return total > 0
        
    except Exception as e:
        logger.error(f"éªŒè¯å¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return False

def main():
    """ä¸»å‡½æ•°"""
    logger.info("å¼€å§‹éªŒè¯ Milvus ä¸­çš„ doc_id å­—æ®µå€¼...")
    
    success = verify_milvus_doc_ids()
    
    if success:
        logger.info("\nğŸ‰ éªŒè¯å®Œæˆ!")
    else:
        logger.error("\nâŒ éªŒè¯å¤±è´¥")
    
    logger.info("éªŒè¯å®Œæˆ")

if __name__ == "__main__":
    main()
